{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e9e4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python39\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import eng_spacysentiment\n",
    "import contractions\n",
    "import spacy\n",
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd68a594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>When I first tuned in on this morning news, I ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mere thoughts of \"Going Overboard\" (aka \"Babes...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why does this movie fall WELL below standards?...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Wow and I thought that any Steven Segal movie ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The story is seen before, but that does'n matt...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24995</td>\n",
       "      <td>Everyone plays their part pretty well in this ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24996</td>\n",
       "      <td>It happened with Assault on Prescient 13 in 20...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24997</td>\n",
       "      <td>My God. This movie was awful. I can't complain...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24998</td>\n",
       "      <td>When I first popped in Happy Birthday to Me, I...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>24999</td>\n",
       "      <td>So why does this show suck? Unfortunately, tha...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            Reviews Sentiment\n",
       "0          0  When I first tuned in on this morning news, I ...       neg\n",
       "1          1  Mere thoughts of \"Going Overboard\" (aka \"Babes...       neg\n",
       "2          2  Why does this movie fall WELL below standards?...       neg\n",
       "3          3  Wow and I thought that any Steven Segal movie ...       neg\n",
       "4          4  The story is seen before, but that does'n matt...       neg\n",
       "...      ...                                                ...       ...\n",
       "24995  24995  Everyone plays their part pretty well in this ...       pos\n",
       "24996  24996  It happened with Assault on Prescient 13 in 20...       neg\n",
       "24997  24997  My God. This movie was awful. I can't complain...       neg\n",
       "24998  24998  When I first popped in Happy Birthday to Me, I...       neg\n",
       "24999  24999  So why does this show suck? Unfortunately, tha...       neg\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment = eng_spacysentiment.load(disable = ['parser'])\n",
    "nlp_sentiment.add_pipe('sentencizer')\n",
    "spacy_model = spacy.load(\"en_core_web_sm\")\n",
    "df = pd.read_csv('data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99e422f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba8588d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for nouns as well\n",
    "\n",
    "def getSentiment(inp_arr):\n",
    "\n",
    "    arr = inp_arr\n",
    "\n",
    "    output = []\n",
    "    \n",
    "    output_dict = {\"data\": None}\n",
    "    token_dict = {\"data\": []}\n",
    "    pos_list = [\"NOUN\", \"PROPN\"]\n",
    "    \n",
    "    if(not isinstance(arr, list)):\n",
    "        doc = nlp_sentiment(arr)\n",
    "        result = doc.cats\n",
    "        result['_id'] = 0\n",
    "        output.append(result)\n",
    "        \n",
    "        spacy_doc = spacy_model(arr)\n",
    "        for token in spacy_doc:\n",
    "            if(token.pos_ in pos_list):\n",
    "                token_dict[\"data\"].append({\"token\": token, \"sentiment\":doc.cats, \"_id\": element[0]})\n",
    "   \n",
    "\n",
    "    elif(isinstance(arr, list)):\n",
    "\n",
    "        for inputs in range(0, len(arr)):\n",
    "            element = arr[inputs].split(\",\")\n",
    "            final_doc = normalizer(element[1])\n",
    "            doc = nlp_sentiment(final_doc[0])\n",
    "            result = doc.cats    \n",
    "            result['_id'] = element[0]\n",
    "            output.append(result)\n",
    "            \n",
    "            spacy_doc = spacy_model(final_doc[0])\n",
    "            for token in spacy_doc:\n",
    "                if(token.pos_ in pos_list):\n",
    "                    \n",
    "                    token_dict[\"data\"].append({\"token\": token, \"sentiment\":doc.cats, \"_id\": element[0]})\n",
    "\n",
    "\n",
    "    output_dict[\"data\"] = output\n",
    "    return output_dict, token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d38f3446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "def normalizer(data):\n",
    "        \n",
    "    doc = TextBlob(data)\n",
    "    final_doc = []\n",
    "    all_sentences = []\n",
    "    \n",
    "    for sentence in doc.sentences:\n",
    "        sentence = sentence.lower()\n",
    "        all_sentences.append(str(sentence))\n",
    "  \n",
    "    return all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "757e6d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1,apple is good\\n', '2,mango is bad\\n', '3,dallas is the beautiful city']\n",
      "[{'positive': 1.0, 'negative': 5.694045679405235e-09, '_id': '1'}, {'positive': 1.7075741197913885e-05, 'negative': 0.9999829530715942, '_id': '2'}, {'positive': 1.0, 'negative': 1.929871193406818e-12, '_id': '3'}]\n",
      "{'token': apple, 'sentiment': {'positive': 1.0, 'negative': 5.694045679405235e-09, '_id': '1'}, '_id': '1'}\n",
      "{'token': mango, 'sentiment': {'positive': 1.7075741197913885e-05, 'negative': 0.9999829530715942, '_id': '2'}, '_id': '2'}\n",
      "{'token': dallas, 'sentiment': {'positive': 1.0, 'negative': 1.929871193406818e-12, '_id': '3'}, '_id': '3'}\n",
      "{'token': city, 'sentiment': {'positive': 1.0, 'negative': 1.929871193406818e-12, '_id': '3'}, '_id': '3'}\n"
     ]
    }
   ],
   "source": [
    "def inputsFromFile(filepath, filename):\n",
    "\n",
    "    with open(os.path.join(filepath, filename)) as f:\n",
    "        lines = f.readlines()\n",
    "    return lines\n",
    "\n",
    "\n",
    "\n",
    "inp = inputsFromFile('', 'sample.csv')\n",
    "print(inp)\n",
    "\n",
    "# print(\"###########\")\n",
    "output, tokens_list = getSentiment(inp)\n",
    "print(output[\"data\"])\n",
    "    \n",
    "for i in tokens_list[\"data\"]:\n",
    "    print(i)\n",
    "# ['1,apple is good\\n', '2,mango is bad\\n', '3,dallas is the beautiful city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f136508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mango is bad\n",
      "PROPN\n",
      "AUX\n",
      "ADJ\n"
     ]
    }
   ],
   "source": [
    "inp = spacy_model(input().lower())\n",
    "for token in inp:\n",
    "    print(token.pos_)\n",
    "# print(getSentiment(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e6cc7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"when i first tuned in on this morning news i thought wow finally some entertainment', 'it was slightly amusing for a week or so', 'but we have to face it these news reporters if one can even call them that have way too much playing around timeat first i thought jillian was a breathe of fresh air', 'but seriously this woman has got not the least bit of journalist in her', 'she is very unprofessional', 'she keeps on interrupting steve when he starts informing the viewers about a certain news report', 'it is just really become annoying to the point that i cannot watch it anymorejillian is not a good journalist', 'hell she is more of a celebrity who loves being a celebrity', 'hence she instantly transforms into a celebrity around celebrities whom she is supposed to be interviewing', 'she is not very professional and quite possibly perceives her relationship with celebrities more important than being a rightfully insatiable journalist and that is all i can say about heralso disappointingly this show has more entertainment news than necessary news reports about the world the government the us or something that will benefit and or serve the publics best interest', 'they are too focus on sensationalism that everything they talk about comes off as a commercial product', 'on the other hand their field reporters are interestingly tolerablei believe good day la is for young teenagers and celebrities and it is definitely not for people who actually care about the newsside note i would really rather watch ktla', 'however they try so hard to be entertaining sometimes', 'they are still a bit dull though', 'oh well i will stick to nbcs today', 'abcs good morning america is also okay as long as diane sawyer does not become way too serious\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = '''when i first tuned in on this morning news i thought wow finally some entertainment', 'it was slightly amusing for a week or so', 'but we have to face it these news reporters if one can even call them that have way too much playing around timeat first i thought jillian was a breathe of fresh air', 'but seriously this woman has got not the least bit of journalist in her', 'she is very unprofessional', 'she keeps on interrupting steve when he starts informing the viewers about a certain news report', 'it is just really become annoying to the point that i cannot watch it anymorejillian is not a good journalist', 'hell she is more of a celebrity who loves being a celebrity', 'hence she instantly transforms into a celebrity around celebrities whom she is supposed to be interviewing', 'she is not very professional and quite possibly perceives her relationship with celebrities more important than being a rightfully insatiable journalist and that is all i can say about heralso disappointingly this show has more entertainment news than necessary news reports about the world the government the us or something that will benefit and or serve the publics best interest', 'they are too focus on sensationalism that everything they talk about comes off as a commercial product', 'on the other hand their field reporters are interestingly tolerablei believe good day la is for young teenagers and celebrities and it is definitely not for people who actually care about the newsside note i would really rather watch ktla', 'however they try so hard to be entertaining sometimes', 'they are still a bit dull though', 'oh well i will stick to nbcs today', 'abcs good morning america is also okay as long as diane sawyer does not become way too serious'''\n",
    "l = normalizer(l)\n",
    "l = ''.join(l)\n",
    "# l[0]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66ca7ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when SCONJ\n",
      "i PRON\n",
      "first ADV\n",
      "tuned VERB\n",
      "in ADP\n",
      "on ADP\n",
      "this DET\n",
      "morning NOUN\n",
      "news NOUN\n",
      "i PRON\n",
      "thought VERB\n",
      "wow INTJ\n",
      "finally ADV\n",
      "some DET\n",
      "entertainment NOUN\n"
     ]
    }
   ],
   "source": [
    "noun_sentiment = {}\n",
    "\n",
    "doc = spacy_model(\"when i first tuned in on this morning news i thought wow finally some entertainment\")\n",
    "for token in doc:\n",
    "#     print(str(token)+\" \"+str(token.pos_))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "58871627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each text data\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "flag = \"\"\n",
    "\n",
    "for i in range(len(df)):\n",
    "    review = df.iloc[i]['Reviews']\n",
    "#     review = normalizer(review)\n",
    "    sent = getSentiment(review.lower())\n",
    "    \n",
    "    if(sent[\"data\"][0][\"positive\"] > sent[\"data\"][0][\"negative\"]):\n",
    "        flag = 'pos'\n",
    "    else:\n",
    "        flag = 'neg'\n",
    "        \n",
    "    if(df.iloc[i]['Sentiment'] == flag):\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f86155d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seperate sentence in the text\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "flag = \"\"\n",
    "\n",
    "for i in range(len(df)):\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    review = df.iloc[i]['Reviews']\n",
    "    review = normalizer(review)\n",
    "    for j in review:\n",
    "        sent = getSentiment(j.lower())\n",
    "        if(sent[\"data\"][0][\"positive\"] > sent[\"data\"][0][\"negative\"]):\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "        \n",
    "        \n",
    "    if(pos > neg):\n",
    "        flag = 'pos'\n",
    "    else:\n",
    "        flag = 'neg'\n",
    "        \n",
    "    if(df.iloc[i]['Sentiment'] == flag):\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c3f60e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17180"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "07c9e6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7820"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c79f825e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17416\n",
      "7584\n"
     ]
    }
   ],
   "source": [
    "# no normalizer\n",
    "print(correct)\n",
    "print(incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c84aa55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "84cf86e6ed6a824144f73d0f7eea89402b55bc47f01d4e2f89e82ad7ea2df663"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
