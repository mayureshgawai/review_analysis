{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e9e4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python39\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import eng_spacysentiment\n",
    "import contractions\n",
    "import spacy\n",
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd68a594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>When I first tuned in on this morning news, I ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mere thoughts of \"Going Overboard\" (aka \"Babes...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why does this movie fall WELL below standards?...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Wow and I thought that any Steven Segal movie ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The story is seen before, but that does'n matt...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24995</td>\n",
       "      <td>Everyone plays their part pretty well in this ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24996</td>\n",
       "      <td>It happened with Assault on Prescient 13 in 20...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24997</td>\n",
       "      <td>My God. This movie was awful. I can't complain...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24998</td>\n",
       "      <td>When I first popped in Happy Birthday to Me, I...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>24999</td>\n",
       "      <td>So why does this show suck? Unfortunately, tha...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            Reviews Sentiment\n",
       "0          0  When I first tuned in on this morning news, I ...       neg\n",
       "1          1  Mere thoughts of \"Going Overboard\" (aka \"Babes...       neg\n",
       "2          2  Why does this movie fall WELL below standards?...       neg\n",
       "3          3  Wow and I thought that any Steven Segal movie ...       neg\n",
       "4          4  The story is seen before, but that does'n matt...       neg\n",
       "...      ...                                                ...       ...\n",
       "24995  24995  Everyone plays their part pretty well in this ...       pos\n",
       "24996  24996  It happened with Assault on Prescient 13 in 20...       neg\n",
       "24997  24997  My God. This movie was awful. I can't complain...       neg\n",
       "24998  24998  When I first popped in Happy Birthday to Me, I...       neg\n",
       "24999  24999  So why does this show suck? Unfortunately, tha...       neg\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment = eng_spacysentiment.load(disable = ['parser'])\n",
    "nlp_sentiment.add_pipe('sentencizer')\n",
    "spacy_model = spacy.load(\"en_core_web_sm\")\n",
    "df = pd.read_csv('data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99e422f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f4ab2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiment(inp_arr):\n",
    "\n",
    "    # arr = normalization(inp_arr)\n",
    "    arr = inp_arr\n",
    "\n",
    "    output = []\n",
    "    output_dict = {\"data\": None}\n",
    "    if(not isinstance(arr, list)):\n",
    "        final_doc = normalizer(arr)\n",
    "        print(final_doc)\n",
    "        doc = nlp_sentiment(final_doc)\n",
    "        result = doc.cats\n",
    "        result['_index'] = 0\n",
    "        output.append(result)\n",
    "\n",
    "    elif(isinstance(arr, list)):\n",
    "        for inputs in range(0, len(arr)):\n",
    "            element = arr[inputs].split(\",\")\n",
    "            print(element)\n",
    "            final_doc = normalizer(element[1])\n",
    "            doc = nlp_sentiment(final_doc)\n",
    "            result = doc.cats    \n",
    "            result['_id'] = element[0]\n",
    "            output.append(result)\n",
    "\n",
    "    output_dict[\"data\"] = output\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "96519f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer(data):\n",
    "        \n",
    "    doc = TextBlob(data)\n",
    "    final_doc = []\n",
    "    all_sentences = []\n",
    "    for sentence in doc.sentences:\n",
    "        \n",
    "        if('but' in sentence[0]):\n",
    "            sentence = sentence.split(\"but\")\n",
    "            \n",
    "            \n",
    "        sentence = sentence.lower()\n",
    "        # contractions removal\n",
    "        sentence_tokens = []\n",
    "        for token in sentence.split(' '):\n",
    "            sentence_tokens.append(contractions.fix(token))\n",
    "        sentence = ' '.join(sentence_tokens)\n",
    "\n",
    "        # Remove Punctuation\n",
    "        sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        # spelling check\n",
    "        sentence = TextBlob(sentence)\n",
    "        sentence = sentence.correct()\n",
    "        all_sentences.append(str(sentence))\n",
    "\n",
    "    final_doc.append(' '.join(all_sentences))\n",
    "    print(final_doc)\n",
    "    return final_doc[0]\n",
    "#     return all_sentences\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9b15b529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "def normalizer(data):\n",
    "        \n",
    "    doc = TextBlob(data)\n",
    "    final_doc = []\n",
    "    all_sentences = []\n",
    "    for sentence in doc.sentences:\n",
    "        \n",
    "        sentences = list(str(sentence))\n",
    "        if('but' in sentences[0]):\n",
    "            sentences = sentences[0].split(\"but\")\n",
    "            \n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.lower()\n",
    "            # contractions removal\n",
    "            sentence_tokens = []\n",
    "            for token in sentence.split(' '):\n",
    "                sentence_tokens.append(contractions.fix(token))\n",
    "            sentence = ' '.join(sentence_tokens)\n",
    "\n",
    "            # Remove Punctuation\n",
    "            sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "            # spelling check\n",
    "            sentence = TextBlob(sentence)\n",
    "            sentence = sentence.correct()\n",
    "            all_sentences.append(str(sentence))\n",
    "\n",
    "#     final_doc.append(' '.join(all_sentences))\n",
    "#     print(final_doc)\n",
    "#     return final_doc[0]\n",
    "    return all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "757e6d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1,apple is good\\n', '2,mango is bad\\n', '3,dallas is the beautiful city']\n",
      "['1', 'apple is good\\n']\n",
      "['apple is good']\n",
      "['2', 'mango is bad\\n']\n",
      "['mange is bad']\n",
      "['3', 'dallas is the beautiful city']\n",
      "['dallas is the beautiful city']\n",
      "{'data': [{'positive': 1.0, 'negative': 5.694045679405235e-09, '_id': '1'}, {'positive': 6.301660853292451e-14, 'negative': 1.0, '_id': '2'}, {'positive': 1.0, 'negative': 1.929871193406818e-12, '_id': '3'}]}\n"
     ]
    }
   ],
   "source": [
    "def inputsFromFile(filepath, filename):\n",
    "\n",
    "    with open(os.path.join(filepath, filename)) as f:\n",
    "        lines = f.readlines()\n",
    "    return lines\n",
    "\n",
    "\n",
    "\n",
    "inp = inputsFromFile('', 'sample.csv')\n",
    "print(inp)\n",
    "print(getSentiment(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5f136508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love staff service food was bad\n",
      "['i love staff service food was bad']\n",
      "i love staff service food was bad\n",
      "{'data': [{'positive': 0.9999994039535522, 'negative': 5.644808993565675e-07, '_index': 0}]}\n"
     ]
    }
   ],
   "source": [
    "inp = input()\n",
    "print(getSentiment(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2cfca9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I <class 'str'> nsubj\n",
      "really <class 'str'> advmod\n",
      "love <class 'str'> ROOT\n",
      "the <class 'str'> det\n",
      "staff <class 'str'> compound\n",
      "service <class 'str'> dobj\n",
      "but <class 'str'> cc\n",
      "the <class 'str'> det\n",
      "food <class 'str'> nsubj\n",
      "was <class 'str'> conj\n",
      "bad <class 'str'> acomp\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"I really love the staff service but the food was bad\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4a90ff5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " ' ',\n",
       " 'r',\n",
       " 'e',\n",
       " 'a',\n",
       " 'l',\n",
       " 'l',\n",
       " 'y',\n",
       " ' ',\n",
       " 'l',\n",
       " 'o',\n",
       " 'v',\n",
       " 'e',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 'f',\n",
       " 'f',\n",
       " ' ',\n",
       " 's',\n",
       " 'e',\n",
       " 'r',\n",
       " 'v',\n",
       " 'i',\n",
       " 'c',\n",
       " 'e',\n",
       " ' ',\n",
       " 'b',\n",
       " 'u',\n",
       " 't',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'f',\n",
       " 'o',\n",
       " 'o',\n",
       " 'd',\n",
       " ' ',\n",
       " 'w',\n",
       " 'a',\n",
       " 's',\n",
       " ' ',\n",
       " 'b',\n",
       " 'a',\n",
       " 'd']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = TextBlob(\"I really love the staff service but the food was bad\")\n",
    "# l = normalizer(l)\n",
    "l = list(l)\n",
    "# l[0]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa795b67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
